{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "tn5W6Sw0D8cS",
    "outputId": "089cc5e1-0a01-4d51-be69-9a34c3bbc868"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import gensim\n",
    "import sqlite3\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn import svm\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import gensim.corpora as corpora\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.externals import joblib\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import ldamulticore, CoherenceModel\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "%autosave 120\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "REEBzBUoD8ck",
    "outputId": "63b1282f-b7f7-441b-fa58-3acd25d3a26a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13757, 81)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"/content/drive/My Drive/ML/data_with_all_tags.csv\")\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qEYskFteD8ct",
    "outputId": "293fed96-8548-4def-b3cc-f99dfa65a90b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13757, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataframe[['title', 'plot_synopsis', 'tags', 'split', 'CleanedSynopsis']]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "yO3BmPrmD8c0",
    "outputId": "ebbdf3ce-085a-4204-979c-90580f595195"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>plot_synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "      <th>CleanedSynopsis</th>\n",
       "      <th>synopsis_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$</td>\n",
       "      <td>Set in Hamburg, West Germany, several criminal...</td>\n",
       "      <td>murder</td>\n",
       "      <td>test</td>\n",
       "      <td>set hamburg west germani sever crimin take adv...</td>\n",
       "      <td>[set, hamburg, west, germani, sever, crimin, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$windle</td>\n",
       "      <td>A 6th grader named Griffin Bing decides to gat...</td>\n",
       "      <td>flashback</td>\n",
       "      <td>train</td>\n",
       "      <td>grader name griffin bing decid gather entir gr...</td>\n",
       "      <td>[grader, name, griffin, bing, decid, gather, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'71</td>\n",
       "      <td>Gary Hook, a new recruit to the British Army, ...</td>\n",
       "      <td>suspenseful, neo noir, murder, violence</td>\n",
       "      <td>train</td>\n",
       "      <td>gari hook new recruit british armi take leav m...</td>\n",
       "      <td>[gari, hook, new, recruit, british, armi, take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'A' gai wak</td>\n",
       "      <td>Sergeant Dragon Ma (Jackie Chan) is part of th...</td>\n",
       "      <td>cult, violence</td>\n",
       "      <td>train</td>\n",
       "      <td>sergeant dragon jacki chan part hong kong mari...</td>\n",
       "      <td>[sergeant, dragon, jacki, chan, part, hong, ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'Breaker' Morant</td>\n",
       "      <td>In Pretoria, South Africa, in 1902, Major Char...</td>\n",
       "      <td>murder, anti war, violence, flashback, tragedy...</td>\n",
       "      <td>train</td>\n",
       "      <td>pretoria south africa major charl bolton rod m...</td>\n",
       "      <td>[pretoria, south, africa, major, charl, bolton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title  ...                                     synopsis_words\n",
       "0                 $  ...  [set, hamburg, west, germani, sever, crimin, t...\n",
       "1           $windle  ...  [grader, name, griffin, bing, decid, gather, e...\n",
       "2               '71  ...  [gari, hook, new, recruit, british, armi, take...\n",
       "3       'A' gai wak  ...  [sergeant, dragon, jacki, chan, part, hong, ko...\n",
       "4  'Breaker' Morant  ...  [pretoria, south, africa, major, charl, bolton...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"synopsis_words\"] = data[\"CleanedSynopsis\"].apply(lambda x: x.split())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MjEkvaBbD8c6"
   },
   "outputs": [],
   "source": [
    "data_words=[]\n",
    "for sent in data[\"synopsis_words\"].values:\n",
    "    data_words.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 690
    },
    "colab_type": "code",
    "id": "qz-ZXXvAD8dB",
    "outputId": "b8735cf6-2786-403d-fbdf-9c84fc86d613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.009*\"kill\" + 0.006*\"father\" + 0.006*\"get\" + 0.005*\"love\" + 0.004*\"famili\" '\n",
      "  '+ 0.004*\"brother\" + 0.004*\"son\" + 0.004*\"meet\" + 0.004*\"take\" + '\n",
      "  '0.004*\"fight\"'),\n",
      " (1,\n",
      "  '0.014*\"tell\" + 0.012*\"go\" + 0.011*\"see\" + 0.011*\"say\" + 0.011*\"back\" + '\n",
      "  '0.010*\"get\" + 0.007*\"ask\" + 0.007*\"find\" + 0.007*\"look\" + 0.007*\"room\"'),\n",
      " (2,\n",
      "  '0.015*\"kill\" + 0.011*\"polic\" + 0.007*\"car\" + 0.006*\"shoot\" + 0.006*\"offic\" '\n",
      "  '+ 0.006*\"frank\" + 0.006*\"man\" + 0.006*\"john\" + 0.006*\"find\" + 0.005*\"gun\"'),\n",
      " (3,\n",
      "  '0.008*\"georg\" + 0.008*\"get\" + 0.008*\"billi\" + 0.007*\"jim\" + 0.007*\"ray\" + '\n",
      "  '0.006*\"scott\" + 0.006*\"go\" + 0.005*\"rachel\" + 0.005*\"find\" + 0.005*\"bella\"'),\n",
      " (4,\n",
      "  '0.009*\"hous\" + 0.008*\"find\" + 0.007*\"mother\" + 0.007*\"mari\" + '\n",
      "  '0.007*\"father\" + 0.006*\"child\" + 0.006*\"kill\" + 0.006*\"home\" + '\n",
      "  '0.005*\"woman\" + 0.005*\"famili\"'),\n",
      " (5,\n",
      "  '0.016*\"go\" + 0.015*\"tell\" + 0.014*\"get\" + 0.012*\"say\" + 0.012*\"sam\" + '\n",
      "  '0.011*\"david\" + 0.009*\"mike\" + 0.009*\"charli\" + 0.008*\"ask\" + '\n",
      "  '0.008*\"sarah\"'),\n",
      " (6,\n",
      "  '0.008*\"human\" + 0.007*\"power\" + 0.006*\"world\" + 0.005*\"use\" + 0.005*\"earth\" '\n",
      "  '+ 0.005*\"destroy\" + 0.004*\"find\" + 0.004*\"one\" + 0.004*\"alien\" + '\n",
      "  '0.004*\"reveal\"'),\n",
      " (7,\n",
      "  '0.006*\"king\" + 0.006*\"kill\" + 0.005*\"return\" + 0.005*\"vampir\" + '\n",
      "  '0.004*\"villag\" + 0.004*\"take\" + 0.004*\"arriv\" + 0.004*\"one\" + '\n",
      "  '0.003*\"father\" + 0.003*\"son\"'),\n",
      " (8,\n",
      "  '0.008*\"kill\" + 0.006*\"war\" + 0.006*\"attack\" + 0.006*\"soldier\" + '\n",
      "  '0.005*\"ship\" + 0.005*\"order\" + 0.005*\"forc\" + 0.005*\"men\" + 0.005*\"group\" + '\n",
      "  '0.005*\"escap\"'),\n",
      " (9,\n",
      "  '0.006*\"new\" + 0.005*\"love\" + 0.005*\"life\" + 0.005*\"time\" + 0.005*\"one\" + '\n",
      "  '0.005*\"friend\" + 0.005*\"make\" + 0.005*\"day\" + 0.004*\"go\" + 0.004*\"film\"')]\n",
      "Time taken to run this cell : 0:30:47.227992\n"
     ]
    }
   ],
   "source": [
    "#Reference: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "start = datetime.now()\n",
    "\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in data_words]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=100,\n",
    "                                           per_word_topics=True,\n",
    "                                           workers=7)\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Qa0Fz2ARD8dI",
    "outputId": "a004b816-696b-4f9e-c6e3-0f56fd8846bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:04:16.213515\n"
     ]
    }
   ],
   "source": [
    "#Reference: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "data_list = dataframe.CleanedSynopsis.values.tolist()\n",
    "\n",
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts = data_list):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_words)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "PdbRaA2OD8dM",
    "outputId": "fa17bdb9-0147-439a-ab5e-b225e89aaf19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6641</td>\n",
       "      <td>kill, polic, car, shoot, offic, frank, man, jo...</td>\n",
       "      <td>[set, hamburg, west, germani, sever, crimin, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2997</td>\n",
       "      <td>go, tell, get, say, sam, david, mike, charli, ...</td>\n",
       "      <td>[grader, name, griffin, bing, decid, gather, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>kill, war, attack, soldier, ship, order, forc,...</td>\n",
       "      <td>[gari, hook, new, recruit, british, armi, take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>kill, war, attack, soldier, ship, order, forc,...</td>\n",
       "      <td>[sergeant, dragon, jacki, chan, part, hong, ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5042</td>\n",
       "      <td>kill, war, attack, soldier, ship, order, forc,...</td>\n",
       "      <td>[pretoria, south, africa, major, charl, bolton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  ...                                               Text\n",
       "0            0  ...  [set, hamburg, west, germani, sever, crimin, t...\n",
       "1            1  ...  [grader, name, griffin, bing, decid, gather, e...\n",
       "2            2  ...  [gari, hook, new, recruit, british, armi, take...\n",
       "3            3  ...  [sergeant, dragon, jacki, chan, part, hong, ko...\n",
       "4            4  ...  [pretoria, south, africa, major, charl, bolton...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bM3Vl_eiD8dO"
   },
   "outputs": [],
   "source": [
    "#Save the top topics in a CSV file.\n",
    "df_dominant_topic.to_csv(\"dominant_topics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdojzvOq4bSi"
   },
   "outputs": [],
   "source": [
    "#Load the topics data\n",
    "df_topic = pd.read_csv(\"/content/drive/My Drive/ML/dominant_topics.csv\")\n",
    "\n",
    "#Combine the processed db with topics db\n",
    "combined_df = pd.concat([data, df_topic], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4UjBGtUED8dU",
    "outputId": "bb780cec-7f33-46aa-d082-83435a253614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points in training data:  10989\n",
      "Number of points in test data:  2768\n"
     ]
    }
   ],
   "source": [
    "#Create a dataset for train and test\n",
    "data_test=combined_df.loc[(combined_df['split'] == 'test')]\n",
    "data_train=combined_df.loc[(combined_df['split'] == 'val') | (combined_df['split'] == 'train')]\n",
    "\n",
    "#Split the whole plot data into train and test set\n",
    "X_train_plots = data_train['CleanedSynopsis']\n",
    "X_test_plots = data_test['CleanedSynopsis']\n",
    "\n",
    "#Split the whole topics data into train and test set\n",
    "X_train_topics = data_train['Keywords']\n",
    "X_test_topics = data_test['Keywords']\n",
    "\n",
    "#Split the tags\n",
    "y_train = data_train['tags']\n",
    "y_test = data_test['tags']\n",
    "\n",
    "print(\"Number of points in training data: \",data_train.shape[0])\n",
    "print(\"Number of points in test data: \",data_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQJBDSGCD8dX"
   },
   "outputs": [],
   "source": [
    "#Importing & Initializing the \"CountVectorizer\" object, which is scikit-learn's bag of words tool. By default 'split()' will tokenize each tag using space.\n",
    "def tokenize(x):\n",
    "    x=x.split(',')\n",
    "    tags=[i.strip() for i in x] #Some tags contains whitespaces before them, so we need to strip them\n",
    "    return tags\n",
    "\n",
    "cnt_vectorizer = CountVectorizer(tokenizer = tokenize, binary='true').fit(y_train)\n",
    "y_train_multilabel = cnt_vectorizer.transform(y_train)\n",
    "y_test_multilabel = cnt_vectorizer.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "po6FToydD8da"
   },
   "source": [
    "<h1> 1. TfidfVectorizer with 1 grams: </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jNe7DTdpD8db",
    "outputId": "e3fe798f-1b0d-4da1-e309-1d1d5c55b4ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:02.923173\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 0.000009, max_features =250000,   tokenizer = lambda x: x.split(\" \"), ngram_range=(1, 1))\n",
    "X_train_plots_multilabel = vectorizer.fit_transform(X_train_plots)\n",
    "X_test_plots_multilabel = vectorizer.transform(X_test_plots)\n",
    "\n",
    "#Use tf-idf vectorizer to vectorize the movie topic synopsis\n",
    "vectorizer = TfidfVectorizer(min_df = 0.000009, max_features =250000,   tokenizer = lambda x: x.split(\" \"),  ngram_range=(1, 1))\n",
    "X_train_topics_multilabel = vectorizer.fit_transform(X_train_topics)\n",
    "X_test_topics_multilabel = vectorizer.transform(X_test_topics)\n",
    "\n",
    "#Combine the sparse matrices into a single sparse matrix\n",
    "from scipy.sparse import hstack\n",
    "X_train_multilabel=hstack([X_train_plots_multilabel,X_train_topics_multilabel])\n",
    "X_test_multilabel=hstack([X_test_plots_multilabel,X_test_topics_multilabel])\n",
    "\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "cWdcBfEID8de",
    "outputId": "3d027b13-bfe4-4b03-ee04-eeee81f8956c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train data X: (10989, 79067) Y : (10989, 71)\n",
      "Dimensions of test data X: (2768, 79067) Y: (2768, 71)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train data X:\",X_train_multilabel.shape, \"Y :\",y_train_multilabel.shape)\n",
    "print(\"Dimensions of test data X:\",X_test_multilabel.shape,\"Y:\",y_test_multilabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1YnDETVD8dh"
   },
   "source": [
    "<h2> 1.1 OneVsRestClassifier + MultinomialNB:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "I5P3JG_BD8dh",
    "outputId": "dc3fd490-0cd7-426c-919f-5d1e3f68473e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=[0.5, 0.5],\n",
       "                                            fit_prior=True),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb = MultinomialNB(class_prior = [0.5, 0.5])\n",
    "\n",
    "clf = OneVsRestClassifier(mb)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nGm917ICD8dk",
    "outputId": "5a37cc37-659a-4a08-d137-2f403ed76392"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision1: 0.6576, recall1: 0.0538, F1-measure: 0.0994\n"
     ]
    }
   ],
   "source": [
    "prediction1 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision1 = precision_score(y_test_multilabel, prediction1, average='micro')\n",
    "\n",
    "recall1 = recall_score(y_test_multilabel, prediction1, average='micro')\n",
    "\n",
    "f1_score1 = 2*((precision1 * recall1)/(precision1 + recall1))\n",
    "\n",
    "print(\"precision1: {:.4f}, recall1: {:.4f}, F1-measure: {:.4f}\".format(precision1, recall1, f1_score1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R81RhVCgD8dn"
   },
   "source": [
    "for i in range(5):\n",
    "    k = data_test.sample(1).index[0]\n",
    "    print(\"Movie: \", data_test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction1[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rO_ZmRucD8dn"
   },
   "source": [
    "<h2> 1.2 OneVsRestClassifier + SGDClassifier with LOG Loss:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "wNq6DfWED8do",
    "outputId": "989ec07c-ce6a-457e-87ab-74a72586544f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight='balanced',\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal', loss='log',\n",
       "                                            max_iter=1000, n_iter_no_change=5,\n",
       "                                            n_jobs=None, penalty='l2',\n",
       "                                            power_t=0.5, random_state=None,\n",
       "                                            shuffle=True, tol=0.001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgl = SGDClassifier(loss='log', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgl)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SD8YXin1D8dq",
    "outputId": "1eea9389-39bc-404f-b6a5-14958a3a3baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision2: 0.2735, recall2: 0.4574, F1-measure: 0.3423\n"
     ]
    }
   ],
   "source": [
    "prediction2 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision2 = precision_score(y_test_multilabel, prediction2, average='micro')\n",
    "\n",
    "recall2 = recall_score(y_test_multilabel, prediction2, average='micro')\n",
    "\n",
    "f1_score2 = 2*((precision2 * recall2)/(precision2 + recall2))\n",
    "\n",
    "print(\"precision2: {:.4f}, recall2: {:.4f}, F1-measure: {:.4f}\".format(precision2, recall2, f1_score2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KP2zTbIcD8ds"
   },
   "source": [
    "for i in range(5):\n",
    "    k = data_test.sample(1).index[0]\n",
    "    print(\"Movie: \", data_test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction2[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_bRYUfttD8dt"
   },
   "source": [
    "<h2> 1.3 OneVsRestClassifier + SGDClassifier with Hinge Loss:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "jUUpW40iD8dt",
    "outputId": "5f599264-cf4c-42c8-95b5-e7739df76687"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight='balanced',\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal',\n",
       "                                            loss='hinge', max_iter=1000,\n",
       "                                            n_iter_no_change=5, n_jobs=None,\n",
       "                                            penalty='l2', power_t=0.5,\n",
       "                                            random_state=None, shuffle=True,\n",
       "                                            tol=0.001, validation_fraction=0.1,\n",
       "                                            verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgh = SGDClassifier(loss='hinge', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgh)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1qRSvoofD8dw",
    "outputId": "fff3488e-1d65-46c7-a4bc-fdee9fce50a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision3: 0.2997, recall3: 0.3835, F1-measure: 0.3364\n"
     ]
    }
   ],
   "source": [
    "prediction3 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision3 = precision_score(y_test_multilabel, prediction3, average='micro')\n",
    "\n",
    "recall3 = recall_score(y_test_multilabel, prediction3, average='micro')\n",
    "\n",
    "f1_score3 = 2*((precision3 * recall3)/(precision3 + recall3))\n",
    "\n",
    "print(\"precision3: {:.4f}, recall3: {:.4f}, F1-measure: {:.4f}\".format(precision3, recall3, f1_score3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1be76OlOD8dy"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction3[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w70z5irUD8dz"
   },
   "source": [
    "<h2> 1.4  OneVsRestClassifier + LogisticRegression:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "RDgUnsAhD8dz",
    "outputId": "e7d6ee21-7a35-4e45-dade-1575b39302e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(lr)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-eYYb-j5D8d1",
    "outputId": "c4cce4b1-1ad3-45a5-83ea-a5795b842920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision4: 0.3019, recall4: 0.4446, F1-measure: 0.3596\n"
     ]
    }
   ],
   "source": [
    "prediction4 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision4 = precision_score(y_test_multilabel, prediction4, average='micro')\n",
    "\n",
    "recall4 = recall_score(y_test_multilabel, prediction4, average='micro')\n",
    "\n",
    "f1_score4 = 2*((precision4 * recall4)/(precision4 + recall4))\n",
    "\n",
    "print(\"precision4: {:.4f}, recall4: {:.4f}, F1-measure: {:.4f}\".format(precision4, recall4, f1_score4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISpPfzLeD8d4"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction4[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owEygk-nD8d5"
   },
   "source": [
    "<h1>2. TfidfVectorizer with (1 - 2 Grams):</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "w5FzaZ4dD8d6",
    "outputId": "82bf7970-e426-48f5-c35a-2bb3e0bae6ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:00:25.287841\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "#Use tf-idf vectorizer to vectorize the movie topic synopsis\n",
    "vectorizer = TfidfVectorizer(min_df = 0.000009, max_features =250000,   tokenizer = lambda x: x.split(\" \"), ngram_range=(1, 2))\n",
    "X_train_plots_multilabel = vectorizer.fit_transform(X_train_plots)\n",
    "X_test_plots_multilabel = vectorizer.transform(X_test_plots)\n",
    "\n",
    "#Use tf-idf vectorizer to vectorize the movie topic synopsis\n",
    "vectorizer = TfidfVectorizer(min_df = 0.000009, max_features =250000,  tokenizer = lambda x: x.split(\" \"),  ngram_range=(1, 2))\n",
    "X_train_topics_multilabel = vectorizer.fit_transform(X_train_topics)\n",
    "X_test_topics_multilabel = vectorizer.transform(X_test_topics)\n",
    "\n",
    "#Combine the sparse matrices into a single sparse matrix\n",
    "from scipy.sparse import hstack\n",
    "X_train_multilabel=hstack([X_train_plots_multilabel,X_train_topics_multilabel])\n",
    "X_test_multilabel=hstack([X_test_plots_multilabel,X_test_topics_multilabel])\n",
    "\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ehZyOiYeD8d8",
    "outputId": "fe3f77c6-d651-495d-fae5-a760ddeb77ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train data X: (10989, 250167) Y : (10989, 71)\n",
      "Dimensions of test data X: (2768, 250167) Y: (2768, 71)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train data X:\",X_train_multilabel.shape, \"Y :\",y_train_multilabel.shape)\n",
    "print(\"Dimensions of test data X:\",X_test_multilabel.shape,\"Y:\",y_test_multilabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JoqlpdZOD8d_"
   },
   "source": [
    "<H2> 2.1 OneVsRestClassifier + MultinomialNB :</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "5fjvxZzjD8d_",
    "outputId": "1c880121-1834-4326-b754-70900abbf392"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=[0.5, 0.5],\n",
       "                                            fit_prior=True),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb = MultinomialNB(class_prior = [0.5, 0.5])\n",
    "\n",
    "clf = OneVsRestClassifier(mb)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EtxmVtyED8eB",
    "outputId": "c21f7387-160f-45b9-e16f-17903deb972e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision5: 0.6786, recall5: 0.0441, F1-measure: 0.0828\n"
     ]
    }
   ],
   "source": [
    "prediction5 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision5 = precision_score(y_test_multilabel, prediction5, average='micro')\n",
    "\n",
    "recall5 = recall_score(y_test_multilabel, prediction5, average='micro')\n",
    "\n",
    "f1_score5 = 2*((precision5 * recall5)/(precision5 + recall5))\n",
    "\n",
    "print(\"precision5: {:.4f}, recall5: {:.4f}, F1-measure: {:.4f}\".format(precision5, recall5, f1_score5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R2eD28ptD8eD"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction5[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h5aoqQswD8eE"
   },
   "source": [
    "<h2> 2.2 OneVsRestClassifier + SGDClassifier with LOG Loss :</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "nP33zWurD8eF",
    "outputId": "3640c620-ec00-4530-ea3d-c8d7f5d933c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight='balanced',\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal', loss='log',\n",
       "                                            max_iter=1000, n_iter_no_change=5,\n",
       "                                            n_jobs=None, penalty='l2',\n",
       "                                            power_t=0.5, random_state=None,\n",
       "                                            shuffle=True, tol=0.001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgl = SGDClassifier(loss='log', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgl)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZiHV9GlXD8eI",
    "outputId": "09bca579-83c7-446e-8827-b477c3071834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision6: 0.2953, recall6: 0.4488, F1-measure: 0.3562\n"
     ]
    }
   ],
   "source": [
    "prediction6 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision6 = precision_score(y_test_multilabel, prediction6, average='micro')\n",
    "\n",
    "recall6 = recall_score(y_test_multilabel, prediction6, average='micro')\n",
    "\n",
    "f1_score6 = 2*((precision6 * recall6)/(precision6 + recall6))\n",
    "\n",
    "print(\"precision6: {:.4f}, recall6: {:.4f}, F1-measure: {:.4f}\".format(precision6, recall6, f1_score6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzAp8lgzD8eK"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction6[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dZ3akcT4D8eK"
   },
   "source": [
    "<h2> 2.3 OneVsRestClassifier + SGDClassifier with HINGE Loss : </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "nbVei9zeD8eL",
    "outputId": "b1bdd086-6765-4e60-d965-0a7f9994bf89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight='balanced',\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal',\n",
       "                                            loss='hinge', max_iter=1000,\n",
       "                                            n_iter_no_change=5, n_jobs=None,\n",
       "                                            penalty='l2', power_t=0.5,\n",
       "                                            random_state=None, shuffle=True,\n",
       "                                            tol=0.001, validation_fraction=0.1,\n",
       "                                            verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgh = SGDClassifier(loss='hinge', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgh)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "LVPMtQVjD8eN",
    "outputId": "6f0b4a8c-1e92-47d1-cf63-20428f25b0a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision7: 0.2711, recall7: 0.3745, F1-measure: 0.3145\n"
     ]
    }
   ],
   "source": [
    "prediction7 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision7 = precision_score(y_test_multilabel, prediction7, average='micro')\n",
    "\n",
    "recall7 = recall_score(y_test_multilabel, prediction7, average='micro')\n",
    "\n",
    "f1_score7 = 2*((precision7 * recall7)/(precision7 + recall7))\n",
    "\n",
    "print(\"precision7: {:.4f}, recall7: {:.4f}, F1-measure: {:.4f}\".format(precision7, recall7, f1_score7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8pz67gNvD8eP"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction7[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q1ocC0RnD8eQ"
   },
   "source": [
    "<h2> 2.4 OneVsRestClassifier + LogisticRegression:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "rl2WtzaBD8eQ",
    "outputId": "c07d06b2-49b4-4b74-bb70-de03d9147449"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(lr)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "DtrQyzJnD8eT",
    "outputId": "9738db79-db9f-40fe-baf0-e0c34a448469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision8: 0.3248, recall8: 0.4399, F1-measure: 0.3737\n"
     ]
    }
   ],
   "source": [
    "prediction8 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision8 = precision_score(y_test_multilabel, prediction8, average='micro')\n",
    "\n",
    "recall8 = recall_score(y_test_multilabel, prediction8, average='micro')\n",
    "\n",
    "f1_score8 = 2*((precision8 * recall8)/(precision8 + recall8))\n",
    "\n",
    "print(\"precision8: {:.4f}, recall8: {:.4f}, F1-measure: {:.4f}\".format(precision8, recall8, f1_score8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80X5aHMOD8eV"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction8[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gceJfFgnD8eW"
   },
   "source": [
    "<h1>3. TfidfVectorizer with (1 - 3 Grams):<?h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PG8XD2VlD8eX",
    "outputId": "7020bdae-fea9-4e7f-df26-92d8b42beef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:01:00.376962\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "#Use tf-idf vectorizer to vectorize the movie topic synopsis\n",
    "vectorizer = TfidfVectorizer(min_df = 0.000009, max_features =250000,   tokenizer = lambda x: x.split(\" \"), ngram_range=(1, 3))\n",
    "X_train_plots_multilabel = vectorizer.fit_transform(X_train_plots)\n",
    "X_test_plots_multilabel = vectorizer.transform(X_test_plots)\n",
    "\n",
    "#Use tf-idf vectorizer to vectorize the movie topic synopsis\n",
    "vectorizer = TfidfVectorizer(min_df = 0.000009, max_features =250000,   tokenizer = lambda x: x.split(\" \"),  ngram_range=(1, 3))\n",
    "X_train_topics_multilabel = vectorizer.fit_transform(X_train_topics)\n",
    "X_test_topics_multilabel = vectorizer.transform(X_test_topics)\n",
    "\n",
    "#Combine the sparse matrices into a single sparse matrix\n",
    "from scipy.sparse import hstack\n",
    "X_train_multilabel=hstack([X_train_plots_multilabel,X_train_topics_multilabel])\n",
    "X_test_multilabel=hstack([X_test_plots_multilabel,X_test_topics_multilabel])\n",
    "\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Sb0SRegOD8eZ",
    "outputId": "680d1f4c-3154-47d0-f612-f4152241cea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train data X: (10989, 250247) Y : (10989, 71)\n",
      "Dimensions of test data X: (2768, 250247) Y: (2768, 71)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train data X:\",X_train_multilabel.shape, \"Y :\",y_train_multilabel.shape)\n",
    "print(\"Dimensions of test data X:\",X_test_multilabel.shape,\"Y:\",y_test_multilabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQ-xwI8aD8ec"
   },
   "source": [
    "<H2> 3.1 OneVsRestClassifier + MultinomialNB :</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "9osyj2JXD8ec",
    "outputId": "1eb012aa-6bc8-420a-bb41-96e59b2523d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=[0.5, 0.5],\n",
       "                                            fit_prior=True),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb = MultinomialNB(class_prior = [0.5, 0.5])\n",
    "\n",
    "clf = OneVsRestClassifier(mb)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "O_bu6AnRD8ef",
    "outputId": "c3f67d35-54d4-43f1-e2ae-a6db7feacdbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision9: 0.6772, recall9: 0.0499, F1-measure: 0.0930\n"
     ]
    }
   ],
   "source": [
    "prediction9 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision9 = precision_score(y_test_multilabel, prediction9, average='micro')\n",
    "\n",
    "recall9 = recall_score(y_test_multilabel, prediction9, average='micro')\n",
    "\n",
    "f1_score9 = 2*((precision9 * recall9)/(precision9 + recall9))\n",
    "\n",
    "print(\"precision9: {:.4f}, recall9: {:.4f}, F1-measure: {:.4f}\".format(precision9, recall9, f1_score9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_8fpYnkD8eh"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction9[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byn5fq7GD8ei"
   },
   "source": [
    "<H2> 3.2 OneVsRestClassifier + SGDClassifier with LOG Loss :</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "pGFnmvQbD8ei",
    "outputId": "888d5256-071b-4c64-b7e8-dc5d70d8220d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight='balanced',\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal', loss='log',\n",
       "                                            max_iter=1000, n_iter_no_change=5,\n",
       "                                            n_jobs=None, penalty='l2',\n",
       "                                            power_t=0.5, random_state=None,\n",
       "                                            shuffle=True, tol=0.001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgl = SGDClassifier(loss='log', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgl)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3jeahicTD8el",
    "outputId": "5c0b4dde-4c9a-4102-f596-a0b2fd0a56b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision10: 0.2991, recall10: 0.4454, F1-measure: 0.3578\n"
     ]
    }
   ],
   "source": [
    "prediction10 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision10 = precision_score(y_test_multilabel, prediction10, average='micro')\n",
    "\n",
    "recall10 = recall_score(y_test_multilabel, prediction10, average='micro')\n",
    "\n",
    "f1_score10 = 2*((precision10 * recall10)/(precision10 + recall10))\n",
    "\n",
    "print(\"precision10: {:.4f}, recall10: {:.4f}, F1-measure: {:.4f}\".format(precision10, recall10, f1_score10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TvJkzKIhD8eo"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction10[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IYX1TxKKD8ep"
   },
   "source": [
    "<h2> 3.3 OneVsRestClassifier + SGDClassifier with HINGE Loss : </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "wBCIs-gbD8eq",
    "outputId": "d99ae050-905d-4d27-b244-6c997be4feba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight='balanced',\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal',\n",
       "                                            loss='hinge', max_iter=1000,\n",
       "                                            n_iter_no_change=5, n_jobs=None,\n",
       "                                            penalty='l2', power_t=0.5,\n",
       "                                            random_state=None, shuffle=True,\n",
       "                                            tol=0.001, validation_fraction=0.1,\n",
       "                                            verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgh = SGDClassifier(loss='hinge', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgh)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "G-XMWdazD8ew",
    "outputId": "cb070a73-edf1-405e-ca75-f60420c5c0ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision11: 0.3308, recall11: 0.3639, F1-measure: 0.3465\n"
     ]
    }
   ],
   "source": [
    "prediction11 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision11 = precision_score(y_test_multilabel, prediction11, average='micro')\n",
    "\n",
    "recall11 = recall_score(y_test_multilabel, prediction11, average='micro')\n",
    "\n",
    "f1_score11 = 2*((precision11 * recall11)/(precision11 + recall11))\n",
    "\n",
    "print(\"precision11: {:.4f}, recall11: {:.4f}, F1-measure: {:.4f}\".format(precision11, recall11, f1_score11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UHofuKvnD8ey"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction11[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6XHfZwjaD8ez"
   },
   "source": [
    "<h2> 3.4 OneVsRestClassifier + LogisticRegression:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "_R2yzt32D8e0",
    "outputId": "e4e0e91f-c9c1-4d7b-e8e1-d173c22c412c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(lr)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Dh21bjSgD8e2",
    "outputId": "f5f6c968-7261-403d-cb08-ff03f4a9e526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision12: 0.3252, recall12: 0.4399, F1-measure: 0.3739\n"
     ]
    }
   ],
   "source": [
    "prediction12 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision12 = precision_score(y_test_multilabel, prediction12, average='micro')\n",
    "\n",
    "recall12 = recall_score(y_test_multilabel, prediction12, average='micro')\n",
    "\n",
    "f1_score12 = 2*((precision12 * recall12)/(precision12 + recall12))\n",
    "\n",
    "print(\"precision12: {:.4f}, recall12: {:.4f}, F1-measure: {:.4f}\".format(precision12, recall12, f1_score12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5kxYR07D8e3"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction12[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4oSTFjaD8e4"
   },
   "source": [
    "<h1>4. TfidfVectorizer with (1 - 4 Grams):</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "hesqnOrqD8e4",
    "outputId": "c2ff8822-4a13-43ed-fc99-543034f1f0c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:01:40.200754\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "#Use tf-idf vectorizer to vectorize the movie topic synopsis\n",
    "vectorizer = TfidfVectorizer(min_df = 0.000009, max_features =250000,   tokenizer = lambda x: x.split(\" \"), ngram_range=(1, 4))\n",
    "X_train_plots_multilabel = vectorizer.fit_transform(X_train_plots)\n",
    "X_test_plots_multilabel = vectorizer.transform(X_test_plots)\n",
    "\n",
    "#Use tf-idf vectorizer to vectorize the movie topic synopsis\n",
    "vectorizer = TfidfVectorizer(min_df = 0.000009, max_features =250000,   tokenizer = lambda x: x.split(\" \"),  ngram_range=(1, 4))\n",
    "X_train_topics_multilabel = vectorizer.fit_transform(X_train_topics)\n",
    "X_test_topics_multilabel = vectorizer.transform(X_test_topics)\n",
    "\n",
    "#Combine the sparse matrices into a single sparse matrix\n",
    "from scipy.sparse import hstack\n",
    "X_train_multilabel=hstack([X_train_plots_multilabel,X_train_topics_multilabel])\n",
    "X_test_multilabel=hstack([X_test_plots_multilabel,X_test_topics_multilabel])\n",
    "\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "1A4cIz5aD8e6",
    "outputId": "324c9ffc-b24c-4bd9-d549-4a4d0c8a4085"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train data X: (10989, 250317) Y : (10989, 71)\n",
      "Dimensions of test data X: (2768, 250317) Y: (2768, 71)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train data X:\",X_train_multilabel.shape, \"Y :\",y_train_multilabel.shape)\n",
    "print(\"Dimensions of test data X:\",X_test_multilabel.shape,\"Y:\",y_test_multilabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KddjzPceD8e8"
   },
   "source": [
    "<H2> 4.1 OneVsRestClassifier + MultinomialNB :</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "86-fua1qD8e8",
    "outputId": "30100558-6e7e-40ba-e06c-00dfea20d323"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=[0.5, 0.5],\n",
       "                                            fit_prior=True),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb = MultinomialNB(class_prior = [0.5, 0.5])\n",
    "\n",
    "clf = OneVsRestClassifier(mb)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5KukieKjD8e_",
    "outputId": "21eacdb4-755e-4b94-efdd-f2dd50f5116e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision13: 0.6700, recall13: 0.0545, F1-measure: 0.1008\n"
     ]
    }
   ],
   "source": [
    "prediction13 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision13 = precision_score(y_test_multilabel, prediction13, average='micro')\n",
    "\n",
    "recall13 = recall_score(y_test_multilabel, prediction13, average='micro')\n",
    "\n",
    "f1_score13 = 2*((precision13 * recall13)/(precision13 + recall13))\n",
    "\n",
    "print(\"precision13: {:.4f}, recall13: {:.4f}, F1-measure: {:.4f}\".format(precision13, recall13, f1_score13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgF-osuZD8fC"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction13[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F45TdNHmD8fD"
   },
   "source": [
    "<h2> 4.2 OneVsRestClassifier + SGDClassifier with LOG Loss :</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "ja-QJc9qD8fD",
    "outputId": "136d1598-67b3-4c0a-aefb-d689f0bfecf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight='balanced',\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal', loss='log',\n",
       "                                            max_iter=1000, n_iter_no_change=5,\n",
       "                                            n_jobs=None, penalty='l2',\n",
       "                                            power_t=0.5, random_state=None,\n",
       "                                            shuffle=True, tol=0.001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgl = SGDClassifier(loss='log', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgl)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cRk3i89uD8fI",
    "outputId": "2578724b-6131-4b22-ecfe-b7c0296897c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision14: 0.2944, recall14: 0.4430, F1-measure: 0.3537\n"
     ]
    }
   ],
   "source": [
    "prediction14 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision14 = precision_score(y_test_multilabel, prediction14, average='micro')\n",
    "\n",
    "recall14 = recall_score(y_test_multilabel, prediction14, average='micro')\n",
    "\n",
    "f1_score14 = 2*((precision14 * recall14)/(precision14 + recall14))\n",
    "\n",
    "print(\"precision14: {:.4f}, recall14: {:.4f}, F1-measure: {:.4f}\".format(precision14, recall14, f1_score14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nkkHO4UTD8fL"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction14[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qB6Rzh1-D8fM"
   },
   "source": [
    "<h2> 4.3 OneVsRestClassifier + SGDClassifier with HINGE Loss : </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "JpIMD5YOD8fM",
    "outputId": "5f189680-68b6-49f8-8630-dc3b094292b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight='balanced',\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal',\n",
       "                                            loss='hinge', max_iter=1000,\n",
       "                                            n_iter_no_change=5, n_jobs=None,\n",
       "                                            penalty='l2', power_t=0.5,\n",
       "                                            random_state=None, shuffle=True,\n",
       "                                            tol=0.001, validation_fraction=0.1,\n",
       "                                            verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgh = SGDClassifier(loss='hinge', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgh)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oADuQeP2D8fO",
    "outputId": "07f3b65a-adab-4984-ad0e-a4e5622abea6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision15: 0.2981, recall15: 0.3634, F1-measure: 0.3275\n"
     ]
    }
   ],
   "source": [
    "prediction15 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision15 = precision_score(y_test_multilabel, prediction15, average='micro')\n",
    "\n",
    "recall15 = recall_score(y_test_multilabel, prediction15, average='micro')\n",
    "\n",
    "f1_score15 = 2*((precision15 * recall15)/(precision15 + recall15))\n",
    "\n",
    "print(\"precision15: {:.4f}, recall15: {:.4f}, F1-measure: {:.4f}\".format(precision15, recall15, f1_score15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lo8sYdtoD8fP"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction15[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUlxo8OCD8fP"
   },
   "source": [
    "<h2> 4.4 OneVsRestClassifier + LogisticRegression:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "hZ3-JyXJD8fQ",
    "outputId": "a3f0eb7f-ac3e-4907-e507-577cfdf80f2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(lr)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SEzxEVV-D8fS",
    "outputId": "eca736f0-4ed8-42a1-a478-a9344f0fa84c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision16: 0.3251, recall16: 0.4400, F1-measure: 0.3739\n"
     ]
    }
   ],
   "source": [
    "prediction16 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision16 = precision_score(y_test_multilabel, prediction16, average='micro')\n",
    "\n",
    "recall16 = recall_score(y_test_multilabel, prediction16, average='micro')\n",
    "\n",
    "f1_score16 = 2*((precision16 * recall16)/(precision16 + recall16))\n",
    "\n",
    "print(\"precision16: {:.4f}, recall16: {:.4f}, F1-measure: {:.4f}\".format(precision16, recall16, f1_score16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oS_ESWH2D8fW"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction16[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2yvGyW8a5DPU"
   },
   "source": [
    "<h1>5. TfidfVectorizer with (1 - 5 Grams):</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9xdlEHPi46Rx",
    "outputId": "235a8657-854c-461e-fcab-08be099a1764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to run this cell : 0:02:15.879856\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "\n",
    "#Use tf-idf vectorizer to vectorize the movie topic synopsis\n",
    "vectorizer = TfidfVectorizer(min_df = 0.000009, max_features =250000,   tokenizer = lambda x: x.split(\" \"), ngram_range=(1, 5))\n",
    "X_train_plots_multilabel = vectorizer.fit_transform(X_train_plots)\n",
    "X_test_plots_multilabel = vectorizer.transform(X_test_plots)\n",
    "\n",
    "#Use tf-idf vectorizer to vectorize the movie topic synopsis\n",
    "vectorizer = TfidfVectorizer(min_df = 0.000009, max_features =250000,   tokenizer = lambda x: x.split(\" \"),  ngram_range=(1, 5))\n",
    "X_train_topics_multilabel = vectorizer.fit_transform(X_train_topics)\n",
    "X_test_topics_multilabel = vectorizer.transform(X_test_topics)\n",
    "\n",
    "#Combine the sparse matrices into a single sparse matrix\n",
    "from scipy.sparse import hstack\n",
    "X_train_multilabel=hstack([X_train_plots_multilabel,X_train_topics_multilabel])\n",
    "X_test_multilabel=hstack([X_test_plots_multilabel,X_test_topics_multilabel])\n",
    "\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "0uBgExql5UCS",
    "outputId": "b03faa3d-f774-486d-c5eb-6a28d846f0f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of train data X: (10989, 250377) Y : (10989, 71)\n",
      "Dimensions of test data X: (2768, 250377) Y: (2768, 71)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of train data X:\",X_train_multilabel.shape, \"Y :\",y_train_multilabel.shape)\n",
    "print(\"Dimensions of test data X:\",X_test_multilabel.shape,\"Y:\",y_test_multilabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eMg533Nj5eXg"
   },
   "source": [
    "<H2> 5.1 OneVsRestClassifier + MultinomialNB :</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "EAAdoHZ95onQ",
    "outputId": "7eaba9f6-6c59-4c6f-f5eb-356071d47dca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=[0.5, 0.5],\n",
       "                                            fit_prior=True),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb = MultinomialNB(class_prior = [0.5, 0.5])\n",
    "\n",
    "clf = OneVsRestClassifier(mb)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zBuHE1E3zyic",
    "outputId": "4c2faaa0-57fd-4dcf-b2de-c5bf68760b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision17: 0.6586, recall17: 0.0572, F1-measure: 0.1052\n"
     ]
    }
   ],
   "source": [
    "prediction17 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision17 = precision_score(y_test_multilabel, prediction17, average='micro')\n",
    "\n",
    "recall17 = recall_score(y_test_multilabel, prediction17, average='micro')\n",
    "\n",
    "f1_score17 = 2*((precision17 * recall17)/(precision17 + recall17))\n",
    "\n",
    "print(\"precision17: {:.4f}, recall17: {:.4f}, F1-measure: {:.4f}\".format(precision17, recall17, f1_score17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1b4rs0m0zyie"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction17[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIdcCSZMzyie"
   },
   "source": [
    "<h2> 5.2 OneVsRestClassifier + SGDClassifier with LOG Loss:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "CBuOsxHOzyif",
    "outputId": "529e6544-6159-4fdb-ec00-cdf0250981b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight='balanced',\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal', loss='log',\n",
       "                                            max_iter=1000, n_iter_no_change=5,\n",
       "                                            n_jobs=None, penalty='l2',\n",
       "                                            power_t=0.5, random_state=None,\n",
       "                                            shuffle=True, tol=0.001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgl = SGDClassifier(loss='log', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgl)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ILMqIvqFzyih",
    "outputId": "b4701770-092f-4575-a8e1-5ca107d1aeb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision18: 0.2934, recall18: 0.4540, F1-measure: 3.2081\n"
     ]
    }
   ],
   "source": [
    "prediction18 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision18 = precision_score(y_test_multilabel, prediction18, average='micro')\n",
    "\n",
    "recall18 = recall_score(y_test_multilabel, prediction18, average='micro')\n",
    "\n",
    "f1_score18 = 18*((precision18 * recall18)/(precision18 + recall18))\n",
    "\n",
    "print(\"precision18: {:.4f}, recall18: {:.4f}, F1-measure: {:.4f}\".format(precision18, recall18, f1_score18))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0valwGozyii"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction18[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6iMCC3AOzyij"
   },
   "source": [
    "<h2> 5.3 OneVsRestClassifier + SGDClassifier with Hinge Loss:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 254
    },
    "colab_type": "code",
    "id": "mZQTBla3zyij",
    "outputId": "a50feb6b-be8d-4685-e49b-df962de4e920"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight='balanced',\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal',\n",
       "                                            loss='hinge', max_iter=1000,\n",
       "                                            n_iter_no_change=5, n_jobs=None,\n",
       "                                            penalty='l2', power_t=0.5,\n",
       "                                            random_state=None, shuffle=True,\n",
       "                                            tol=0.001, validation_fraction=0.1,\n",
       "                                            verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgh = SGDClassifier(loss='hinge', class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(sgh)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mZO_A6gAzyil",
    "outputId": "9eb1d48b-ba85-48ac-c122-8cfdc74fd5b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision19: 0.2467, recall19: 0.3770, F1-measure: 0.2983\n"
     ]
    }
   ],
   "source": [
    "prediction19 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision19 = precision_score(y_test_multilabel, prediction19, average='micro')\n",
    "\n",
    "recall19 = recall_score(y_test_multilabel, prediction19, average='micro')\n",
    "\n",
    "f1_score19 = 2*((precision19 * recall19)/(precision19 + recall19))\n",
    "\n",
    "print(\"precision19: {:.4f}, recall19: {:.4f}, F1-measure: {:.4f}\".format(precision19, recall19, f1_score19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wlvOYJZzyim"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction19[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAftZcPdzyim"
   },
   "source": [
    "<h2> 5.4  OneVsRestClassifier + LogisticRegression:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "xpkzW0L1zyin",
    "outputId": "f436450c-7380-4159-857c-a9ef079f4356"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "clf = OneVsRestClassifier(lr)\n",
    "clf.fit(X_train_multilabel, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "RD9ZsQSlzyio",
    "outputId": "0a45a476-92fb-4d53-fa4a-ed6816334180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision20: 0.3249, recall20: 0.4400, F1-measure: 0.3738\n"
     ]
    }
   ],
   "source": [
    "prediction20 = clf.predict(X_test_multilabel)\n",
    "\n",
    "precision20 = precision_score(y_test_multilabel, prediction20, average='micro')\n",
    "\n",
    "recall20 = recall_score(y_test_multilabel, prediction20, average='micro')\n",
    "\n",
    "f1_score20 = 2*((precision20 * recall20)/(precision20 + recall20))\n",
    "\n",
    "print(\"precision20: {:.4f}, recall20: {:.4f}, F1-measure: {:.4f}\".format(precision20, recall20, f1_score20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMduB7vyzyit"
   },
   "source": [
    "for i in range(5):\n",
    "    k = test.sample(1).index[0]\n",
    "    print(\"Movie: \", test['title'][k]) \n",
    "    print(\"Actual genre: \",y_test[k])\n",
    "    print(\"Predicted tag: \", cnt_vectorizer.inverse_transform(prediction20[k])[0],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7FD1n-kD8fW"
   },
   "source": [
    "<h1> Conclusion: </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "colab_type": "code",
    "id": "kLxj25CqD8fW",
    "outputId": "98046bc3-d068-44a1-e79f-34b03840cb28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------+--------+-----------+--------+----------+\n",
      "|        Model         |    Vectorizer   | ngrams | Precision | recall | f1_score |\n",
      "+----------------------+-----------------+--------+-----------+--------+----------+\n",
      "|    MultinomialNB     | TfidfVectorizer | (1, 1) |   0.658   | 0.054  |  0.099   |\n",
      "|  SGDClassifier(log)  | TfidfVectorizer | (1, 1) |   0.273   | 0.457  |  0.342   |\n",
      "| SGDClassifier(hinge) | TfidfVectorizer | (1, 1) |    0.3    | 0.383  |  0.336   |\n",
      "|  LogisticRegression  | TfidfVectorizer | (1, 1) |   0.302   | 0.445  |   0.36   |\n",
      "|                      |                 |        |           |        |          |\n",
      "|                      |                 |        |           |        |          |\n",
      "|    MultinomialNB     | TfidfVectorizer | (1, 2) |   0.679   | 0.044  |  0.083   |\n",
      "|  SGDClassifier(log)  | TfidfVectorizer | (1, 2) |   0.295   | 0.449  |  0.356   |\n",
      "| SGDClassifier(hinge) | TfidfVectorizer | (1, 2) |   0.271   | 0.374  |  0.314   |\n",
      "|  LogisticRegression  | TfidfVectorizer | (1, 2) |   0.325   |  0.44  |  0.374   |\n",
      "|                      |                 |        |           |        |          |\n",
      "|                      |                 |        |           |        |          |\n",
      "|    MultinomialNB     | TfidfVectorizer | (1, 3) |   0.677   |  0.05  |  0.093   |\n",
      "|  SGDClassifier(log)  | TfidfVectorizer | (1, 3) |   0.299   | 0.445  |  0.358   |\n",
      "| SGDClassifier(hinge) | TfidfVectorizer | (1, 3) |   0.331   | 0.364  |  0.347   |\n",
      "|  LogisticRegression  | TfidfVectorizer | (1, 3) |   0.325   |  0.44  |  0.374   |\n",
      "|                      |                 |        |           |        |          |\n",
      "|                      |                 |        |           |        |          |\n",
      "|    MultinomialNB     | TfidfVectorizer | (1, 4) |    0.67   | 0.054  |  0.101   |\n",
      "|  SGDClassifier(log)  | TfidfVectorizer | (1, 4) |   0.294   | 0.443  |  0.354   |\n",
      "| SGDClassifier(hinge) | TfidfVectorizer | (1, 4) |   0.298   | 0.363  |  0.327   |\n",
      "|  LogisticRegression  | TfidfVectorizer | (1, 4) |   0.325   |  0.44  |  0.374   |\n",
      "|                      |                 |        |           |        |          |\n",
      "|                      |                 |        |           |        |          |\n",
      "|    MultinomialNB     | TfidfVectorizer | (1, 5) |   0.659   | 0.057  |  0.105   |\n",
      "|  SGDClassifier(log)  | TfidfVectorizer | (1, 5) |   0.293   | 0.454  |  3.208   |\n",
      "| SGDClassifier(hinge) | TfidfVectorizer | (1, 5) |   0.247   | 0.377  |  0.298   |\n",
      "|  LogisticRegression  | TfidfVectorizer | (1, 5) |   0.325   |  0.44  |  0.374   |\n",
      "+----------------------+-----------------+--------+-----------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "tabel = PrettyTable()\n",
    "\n",
    "tabel.field_names=['Model','Vectorizer','ngrams','Precision','recall','f1_score']\n",
    "\n",
    "\n",
    "\n",
    "tabel.add_row(['MultinomialNB', 'TfidfVectorizer', '(1, 1)', round(precision1, 3),round(recall1, 3), round(f1_score1, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(log)', 'TfidfVectorizer', '(1, 1)', round(precision2, 3), round(recall2, 3), round(f1_score2, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(hinge)','TfidfVectorizer','(1, 1)' ,round(precision3, 3),  round(recall3, 3), round(f1_score3, 3)])\n",
    "\n",
    "tabel.add_row(['LogisticRegression','TfidfVectorizer','(1, 1)', round(precision4, 3), round(recall4, 3), round(f1_score4, 3)])\n",
    "\n",
    "tabel.add_row(['','','','','',''])\n",
    "tabel.add_row(['','','','','',''])\n",
    "\n",
    "\n",
    "tabel.add_row(['MultinomialNB', 'TfidfVectorizer', '(1, 2)', round(precision5, 3), round(recall5, 3),  round(f1_score5, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(log)', 'TfidfVectorizer', '(1, 2)', round(precision6, 3),  round(recall6, 3),  round(f1_score6, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(hinge)','TfidfVectorizer','(1, 2)', round(precision7, 3),  round(recall7, 3),  round(f1_score7, 3)])\n",
    "\n",
    "tabel.add_row(['LogisticRegression','TfidfVectorizer','(1, 2)', round(precision8, 3),  round(recall8, 3),  round(f1_score8, 3)])\n",
    "\n",
    "tabel.add_row(['','','','','',''])\n",
    "tabel.add_row(['','','','','',''])\n",
    "\n",
    "\n",
    "tabel.add_row(['MultinomialNB', 'TfidfVectorizer', '(1, 3)', round(precision9, 3),  round(recall9, 3), round(f1_score9, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(log)', 'TfidfVectorizer', '(1, 3)', round(precision10, 3),  round(recall10, 3), round(f1_score10, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(hinge)','TfidfVectorizer','(1, 3)', round(precision11, 3),  round(recall11, 3), round(f1_score11, 3)])\n",
    "\n",
    "tabel.add_row(['LogisticRegression','TfidfVectorizer','(1, 3)', round(precision12, 3),  round(recall12, 3), round(f1_score12, 3)])\n",
    "\n",
    "tabel.add_row(['','','','','',''])\n",
    "tabel.add_row(['','','','','',''])\n",
    "\n",
    "tabel.add_row(['MultinomialNB', 'TfidfVectorizer', '(1, 4)', round(precision13, 3), round(recall13, 3), round(f1_score13, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(log)', 'TfidfVectorizer', '(1, 4)', round(precision14, 3), round(recall14, 3), round(f1_score14, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(hinge)','TfidfVectorizer','(1, 4)', round(precision15, 3), round(recall15, 3), round(f1_score15, 3)])\n",
    "\n",
    "tabel.add_row(['LogisticRegression','TfidfVectorizer','(1, 4)', round(precision16, 3),  round(recall16, 3),  round(f1_score16, 3)])\n",
    "\n",
    "\n",
    "tabel.add_row(['','','','','',''])\n",
    "tabel.add_row(['','','','','',''])\n",
    "\n",
    "tabel.add_row(['MultinomialNB', 'TfidfVectorizer', '(1, 5)', round(precision17, 3), round(recall17, 3), round(f1_score17, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(log)', 'TfidfVectorizer', '(1, 5)', round(precision18, 3), round(recall18, 3), round(f1_score18, 3)])\n",
    "\n",
    "tabel.add_row(['SGDClassifier(hinge)','TfidfVectorizer','(1, 5)', round(precision19, 3), round(recall19, 3), round(f1_score19, 3)])\n",
    "\n",
    "tabel.add_row(['LogisticRegression','TfidfVectorizer','(1, 5)', round(precision20, 3),  round(recall20, 3),  round(f1_score20, 3)])\n",
    "\n",
    "print(tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Topic Modelling, I had tried many variations but  the maximum f1 score we are getting is 0.374 for LogisticRegression But in a particular case that is SGDClassifier with (1, 5) grams we got the f1 score of 3.208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Topic_Modelling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
